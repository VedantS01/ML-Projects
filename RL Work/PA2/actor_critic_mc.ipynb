{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jQ1tEQCxwRx"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:23:11.270433Z",
     "iopub.status.busy": "2022-01-26T05:23:11.269836Z",
     "iopub.status.idle": "2022-01-26T05:23:13.774671Z",
     "shell.execute_reply": "2022-01-26T05:23:13.774154Z"
    },
    "id": "tT4N3qYviUJr"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import gym\n",
    "import numpy as np\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from typing import Any, List, Sequence, Tuple\n",
    "\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "# Set seed for experiment reproducibility\n",
    "seed = 42\n",
    "env.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Small epsilon value for stabilizing division operations\n",
    "eps = np.finfo(np.float32).eps.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:23:13.781209Z",
     "iopub.status.busy": "2022-01-26T05:23:13.780629Z",
     "iopub.status.idle": "2022-01-26T05:23:13.782635Z",
     "shell.execute_reply": "2022-01-26T05:23:13.782236Z"
    },
    "id": "aXKbbMC-kmuv"
   },
   "outputs": [],
   "source": [
    "class ActorCritic(tf.keras.Model):\n",
    "  \"\"\"Combined actor-critic network.\"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self, \n",
    "      num_actions: int, \n",
    "      num_hidden_units1: int,\n",
    "      num_hidden_units2: int):\n",
    "    \"\"\"Initialize.\"\"\"\n",
    "    super().__init__()\n",
    "\n",
    "    self.common2 = layers.Dense(num_hidden_units2, activation=\"relu\")\n",
    "    self.common1 = layers.Dense(num_hidden_units1, activation=\"relu\")\n",
    "    self.actor = layers.Dense(num_actions)\n",
    "    self.critic = layers.Dense(1)\n",
    "\n",
    "  def call(self, inputs: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    x = self.common1(inputs)\n",
    "    y = self.common2(x)\n",
    "    return self.actor(y), self.critic(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:23:13.787513Z",
     "iopub.status.busy": "2022-01-26T05:23:13.786039Z",
     "iopub.status.idle": "2022-01-26T05:23:15.327234Z",
     "shell.execute_reply": "2022-01-26T05:23:15.327656Z"
    },
    "id": "nWyxJgjLn68c"
   },
   "outputs": [],
   "source": [
    "num_actions = env.action_space.n  # 2\n",
    "num_hidden_units1 = 12\n",
    "num_hidden_units2 = 12\n",
    "\n",
    "model = ActorCritic(num_actions, num_hidden_units1,num_hidden_units2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:23:15.334407Z",
     "iopub.status.busy": "2022-01-26T05:23:15.333557Z",
     "iopub.status.idle": "2022-01-26T05:23:15.335339Z",
     "shell.execute_reply": "2022-01-26T05:23:15.335713Z"
    },
    "id": "5URrbGlDSAGx"
   },
   "outputs": [],
   "source": [
    "# Wrap OpenAI Gym's `env.step` call as an operation in a TensorFlow function.\n",
    "# This would allow it to be included in a callable TensorFlow graph.\n",
    "\n",
    "def env_step(action: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "  \"\"\"Returns state, reward and done flag given an action.\"\"\"\n",
    "\n",
    "  state, reward, done, _ = env.step(action)\n",
    "  return (state.astype(np.float32), \n",
    "          np.array(reward, np.int32), \n",
    "          np.array(done, np.int32))\n",
    "\n",
    "\n",
    "def tf_env_step(action: tf.Tensor) -> List[tf.Tensor]:\n",
    "  return tf.numpy_function(env_step, [action], \n",
    "                           [tf.float32, tf.int32, tf.int32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:23:15.343778Z",
     "iopub.status.busy": "2022-01-26T05:23:15.343000Z",
     "iopub.status.idle": "2022-01-26T05:23:15.344931Z",
     "shell.execute_reply": "2022-01-26T05:23:15.345267Z"
    },
    "id": "a4qVRV063Cl9"
   },
   "outputs": [],
   "source": [
    "def run_episode(\n",
    "    initial_state: tf.Tensor,  \n",
    "    model: tf.keras.Model, \n",
    "    max_steps: int) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "  \"\"\"Runs a single episode to collect training data.\"\"\"\n",
    "\n",
    "  action_probs = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "  values = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "  rewards = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
    "\n",
    "  initial_state_shape = initial_state.shape\n",
    "  state = initial_state\n",
    "\n",
    "  for t in tf.range(max_steps):\n",
    "    # Convert state into a batched tensor (batch size = 1)\n",
    "    state = tf.expand_dims(state, 0)\n",
    "  \n",
    "    # Run the model and to get action probabilities and critic value\n",
    "    action_logits_t, value = model(state)\n",
    "  \n",
    "    # Sample next action from the action probability distribution\n",
    "    action = tf.random.categorical(action_logits_t, 1)[0, 0]\n",
    "    action_probs_t = tf.nn.softmax(action_logits_t)\n",
    "\n",
    "    # Store critic values\n",
    "    values = values.write(t, tf.squeeze(value))\n",
    "\n",
    "    # Store log probability of the action chosen\n",
    "    action_probs = action_probs.write(t, action_probs_t[0, action])\n",
    "  \n",
    "    # Apply action to the environment to get next state and reward\n",
    "    state, reward, done = tf_env_step(action)\n",
    "    reward = reward*100000 + int(state[1]*100)\n",
    "    state.set_shape(initial_state_shape)\n",
    "  \n",
    "    # Store reward\n",
    "    rewards = rewards.write(t, reward)\n",
    "\n",
    "    if tf.cast(done, tf.bool):\n",
    "      break\n",
    "\n",
    "  action_probs = action_probs.stack()\n",
    "  values = values.stack()\n",
    "  rewards = rewards.stack()\n",
    "  \n",
    "  return action_probs, values, rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBnIHdz22dIx"
   },
   "source": [
    "### 2. Computing expected returns\n",
    "\n",
    "The sequence of rewards for each timestep $t$, $\\{r_{t}\\}^{T}_{t=1}$ collected during one episode is converted into a sequence of expected returns $\\{G_{t}\\}^{T}_{t=1}$ in which the sum of rewards is taken from the current timestep $t$ to $T$ and each reward is multiplied with an exponentially decaying discount factor $\\gamma$:\n",
    "\n",
    "$$G_{t} = \\sum^{T}_{t'=t} \\gamma^{t'-t}r_{t'}$$\n",
    "\n",
    "Since $\\gamma\\in(0,1)$, rewards further out from the current timestep are given less weight.\n",
    "\n",
    "Intuitively, expected return simply implies that rewards now are better than rewards later. In a mathematical sense, it is to ensure that the sum of the rewards converges.\n",
    "\n",
    "To stabilize training, the resulting sequence of returns is also standardized (i.e. to have zero mean and unit standard deviation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:23:15.351637Z",
     "iopub.status.busy": "2022-01-26T05:23:15.350879Z",
     "iopub.status.idle": "2022-01-26T05:23:15.353333Z",
     "shell.execute_reply": "2022-01-26T05:23:15.352864Z"
    },
    "id": "jpEwFyl315dl"
   },
   "outputs": [],
   "source": [
    "def get_expected_return(\n",
    "    rewards: tf.Tensor, \n",
    "    gamma: float, \n",
    "    standardize: bool = True) -> tf.Tensor:\n",
    "  \"\"\"Compute expected returns per timestep.\"\"\"\n",
    "\n",
    "  n = tf.shape(rewards)[0]\n",
    "  returns = tf.TensorArray(dtype=tf.float32, size=n)\n",
    "\n",
    "  # Start from the end of `rewards` and accumulate reward sums\n",
    "  # into the `returns` array\n",
    "  rewards = tf.cast(rewards[::-1], dtype=tf.float32)\n",
    "  discounted_sum = tf.constant(0.0)\n",
    "  discounted_sum_shape = discounted_sum.shape\n",
    "  for i in tf.range(n):\n",
    "    reward = rewards[i]\n",
    "    discounted_sum = reward + gamma * discounted_sum\n",
    "    discounted_sum.set_shape(discounted_sum_shape)\n",
    "    returns = returns.write(i, discounted_sum)\n",
    "  returns = returns.stack()[::-1]\n",
    "\n",
    "  if standardize:\n",
    "    returns = ((returns - tf.math.reduce_mean(returns)) / \n",
    "               (tf.math.reduce_std(returns) + eps))\n",
    "\n",
    "  return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hrPLrgGxlvb"
   },
   "source": [
    "### 3. The actor-critic loss\n",
    "\n",
    "Since a hybrid actor-critic model is used, the chosen loss function is a combination of actor and critic losses for training, as shown below:\n",
    "\n",
    "$$L = L_{actor} + L_{critic}$$\n",
    "\n",
    "#### Actor loss\n",
    "\n",
    "The actor loss is based on [policy gradients with the critic as a state dependent baseline](https://www.youtube.com/watch?v=EKqxumCuAAY&t=62m23s) and computed with single-sample (per-episode) estimates.\n",
    "\n",
    "$$L_{actor} = -\\sum^{T}_{t=1} \\log\\pi_{\\theta}(a_{t} | s_{t})[G(s_{t}, a_{t})  - V^{\\pi}_{\\theta}(s_{t})]$$\n",
    "\n",
    "where:\n",
    "- $T$: the number of timesteps per episode, which can vary per episode\n",
    "- $s_{t}$: the state at timestep $t$\n",
    "- $a_{t}$: chosen action at timestep $t$ given state $s$\n",
    "- $\\pi_{\\theta}$: is the policy (actor) parameterized by $\\theta$\n",
    "- $V^{\\pi}_{\\theta}$: is the value function (critic) also parameterized by $\\theta$\n",
    "- $G = G_{t}$: the expected return for a given state, action pair at timestep $t$\n",
    "\n",
    "A negative term is added to the sum since the idea is to maximize the probabilities of actions yielding higher rewards by minimizing the combined loss.\n",
    "\n",
    "<br>\n",
    "\n",
    "##### Advantage\n",
    "\n",
    "The $G - V$ term in our $L_{actor}$ formulation is called the [advantage](https://spinningup.openai.com/en/latest/spinningup/rl_intro.html#advantage-functions), which indicates how much better an action is given a particular state over a random action selected according to the policy $\\pi$ for that state.\n",
    "\n",
    "While it's possible to exclude a baseline, this may result in high variance during training. And the nice thing about choosing the critic $V$ as a baseline is that it trained to be as close as possible to $G$, leading to a lower variance.\n",
    "\n",
    "In addition, without the critic, the algorithm would try to increase probabilities for actions taken on a particular state based on expected return, which may not make much of a difference if the relative probabilities between actions remain the same.\n",
    "\n",
    "For instance, suppose that two actions for a given state would yield the same expected return. Without the critic, the algorithm would try to raise the probability of these actions based on the objective $J$. With the critic, it may turn out that there's no advantage ($G - V = 0$) and thus no benefit gained in increasing the actions' probabilities and the algorithm would set the gradients to zero.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Critic loss\n",
    "\n",
    "Training $V$ to be as close possible to $G$ can be set up as a regression problem with the following loss function:\n",
    "\n",
    "$$L_{critic} = L_{\\delta}(G, V^{\\pi}_{\\theta})$$\n",
    "\n",
    "where $L_{\\delta}$ is the [Huber loss](https://en.wikipedia.org/wiki/Huber_loss), which is less sensitive to outliers in data than squared-error loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:23:15.358845Z",
     "iopub.status.busy": "2022-01-26T05:23:15.358077Z",
     "iopub.status.idle": "2022-01-26T05:23:15.360025Z",
     "shell.execute_reply": "2022-01-26T05:23:15.360372Z"
    },
    "id": "9EXwbEez6n9m"
   },
   "outputs": [],
   "source": [
    "huber_loss = tf.keras.losses.Huber(reduction=tf.keras.losses.Reduction.SUM)\n",
    "\n",
    "def compute_loss(\n",
    "    action_probs: tf.Tensor,  \n",
    "    values: tf.Tensor,  \n",
    "    returns: tf.Tensor) -> tf.Tensor:\n",
    "  \"\"\"Computes the combined actor-critic loss.\"\"\"\n",
    "\n",
    "  advantage = returns - values\n",
    "\n",
    "  action_log_probs = tf.math.log(action_probs)\n",
    "  actor_loss = -tf.math.reduce_sum(action_log_probs * advantage)\n",
    "\n",
    "  critic_loss = huber_loss(values, returns)\n",
    "\n",
    "  return actor_loss + critic_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSYkQOmRfV75"
   },
   "source": [
    "### 4. Defining the training step to update parameters\n",
    "\n",
    "All of the steps above are combined into a training step that is run every episode. All steps leading up to the loss function are executed with the `tf.GradientTape` context to enable automatic differentiation.\n",
    "\n",
    "This tutorial uses the Adam optimizer to apply the gradients to the model parameters.\n",
    "\n",
    "The sum of the undiscounted rewards, `episode_reward`, is also computed in this step. This value will be used later on to evaluate if the success criterion is met.\n",
    "\n",
    "The `tf.function` context is applied to the `train_step` function so that it can be compiled into a callable TensorFlow graph, which can lead to 10x speedup in training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:23:15.367094Z",
     "iopub.status.busy": "2022-01-26T05:23:15.366298Z",
     "iopub.status.idle": "2022-01-26T05:23:15.368110Z",
     "shell.execute_reply": "2022-01-26T05:23:15.368545Z"
    },
    "id": "QoccrkF3IFCg"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(\n",
    "    initial_state: tf.Tensor, \n",
    "    model: tf.keras.Model, \n",
    "    optimizer: tf.keras.optimizers.Optimizer, \n",
    "    gamma: float, \n",
    "    max_steps_per_episode: int) -> tf.Tensor:\n",
    "  \"\"\"Runs a model training step.\"\"\"\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "\n",
    "    # Run the model for one episode to collect training data\n",
    "    action_probs, values, rewards = run_episode(\n",
    "        initial_state, model, max_steps_per_episode) \n",
    "\n",
    "    # Calculate expected returns\n",
    "    returns = get_expected_return(rewards, gamma)\n",
    "\n",
    "    # Convert training data to appropriate TF tensor shapes\n",
    "    action_probs, values, returns = [\n",
    "        tf.expand_dims(x, 1) for x in [action_probs, values, returns]] \n",
    "\n",
    "    # Calculating loss values to update our network\n",
    "    loss = compute_loss(action_probs, values, returns)\n",
    "\n",
    "  # Compute the gradients from the loss\n",
    "  grads = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "  # Apply the gradients to the model's parameters\n",
    "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "  episode_reward = tf.math.reduce_sum(rewards)\n",
    "\n",
    "  return episode_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFvZiDoAflGK"
   },
   "source": [
    "### 5. Run the training loop\n",
    "\n",
    "Training is executed by running the training step until either the success criterion or maximum number of episodes is reached.  \n",
    "\n",
    "A running record of episode rewards is kept in a queue. Once 100 trials are reached, the oldest reward is removed at the left (tail) end of the queue and the newest one is added at the head (right). A running sum of the rewards is also maintained for computational efficiency. \n",
    "\n",
    "Depending on your runtime, training can finish in less than a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:23:15.374476Z",
     "iopub.status.busy": "2022-01-26T05:23:15.373652Z",
     "iopub.status.idle": "2022-01-26T05:24:28.546242Z",
     "shell.execute_reply": "2022-01-26T05:24:28.546605Z"
    },
    "id": "kbmBxnzLiUJx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Vedant\\AppData\\Local\\Temp\\ipykernel_33112\\892927516.py\", line 16, in train_step  *\n        action_probs, values, rewards = run_episode(\n    File \"C:\\Users\\Vedant\\AppData\\Local\\Temp\\ipykernel_33112\\2969055968.py\", line 36, in run_episode  *\n        rewards = rewards.write(t, np.int32(reward*100000 + state[1]*100))\n\n    TypeError: Input 'y' of 'AddV2' Op has type float32 that does not match type int32 of argument 'x'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Vedant/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/util/traceback_utils.py?line=152'>153</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/util/traceback_utils.py?line=153'>154</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/util/traceback_utils.py?line=154'>155</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/framework/func_graph.py?line=1144'>1145</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/framework/func_graph.py?line=1145'>1146</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Vedant/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/framework/func_graph.py?line=1146'>1147</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/framework/func_graph.py?line=1147'>1148</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/framework/func_graph.py?line=1148'>1149</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Vedant\\AppData\\Local\\Temp\\ipykernel_33112\\892927516.py\", line 16, in train_step  *\n        action_probs, values, rewards = run_episode(\n    File \"C:\\Users\\Vedant\\AppData\\Local\\Temp\\ipykernel_33112\\2969055968.py\", line 36, in run_episode  *\n        rewards = rewards.write(t, np.int32(reward*100000 + state[1]*100))\n\n    TypeError: Input 'y' of 'AddV2' Op has type float32 that does not match type int32 of argument 'x'.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "min_episodes_criterion = 100\n",
    "max_episodes = 10000\n",
    "max_steps_per_episode = 1000\n",
    "\n",
    "# Cartpole-v0 is considered solved if average reward is >= 195 over 100 \n",
    "# consecutive trials\n",
    "reward_threshold = 195\n",
    "running_reward = 0\n",
    "\n",
    "# Discount factor for future rewards\n",
    "gamma = 0.99\n",
    "\n",
    "# Keep last episodes reward\n",
    "episodes_reward: collections.deque = collections.deque(maxlen=min_episodes_criterion)\n",
    "\n",
    "# rewards\n",
    "rewards = []\n",
    "\n",
    "with tqdm.trange(max_episodes) as t:\n",
    "  for i in t:\n",
    "    initial_state = tf.constant(env.reset(), dtype=tf.float32)\n",
    "    episode_reward = int(train_step(\n",
    "        initial_state, model, optimizer, gamma, max_steps_per_episode))\n",
    "    \n",
    "    rewards.append(episode_reward)\n",
    "    \n",
    "    episodes_reward.append(episode_reward)\n",
    "    running_reward = statistics.mean(episodes_reward)\n",
    "  \n",
    "    t.set_description(f'Episode {i}')\n",
    "    t.set_postfix(\n",
    "        episode_reward=episode_reward, running_reward=running_reward)\n",
    "  \n",
    "    # Show average episode reward every 10 episodes\n",
    "    if i % 10 == 0:\n",
    "      pass # print(f'Episode {i}: average reward: {avg_reward}')\n",
    "  \n",
    "    # if running_reward > reward_threshold and i >= min_episodes_criterion:  \n",
    "    #     break\n",
    "\n",
    "print(f'\\nSolved at episode {i}: average reward: {running_reward:.2f}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27b156a7c70>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "avg_plot = []\n",
    "for i in range(len(rewards)):\n",
    "    if(i >= 100):\n",
    "        avg_plot.append(np.mean(rewards[i-100:i+1]))\n",
    "    else:\n",
    "        avg_plot.append(np.mean(rewards[0:i+1]))\n",
    "    # rewards[i] = avg_plot[i]\n",
    "plt.plot(avg_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ru8BEwS1EmAv"
   },
   "source": [
    "## Visualization\n",
    "\n",
    "After training, it would be good to visualize how the model performs in the environment. You can run the cells below to generate a GIF animation of one episode run of the model. Note that additional packages need to be installed for OpenAI Gym to render the environment's images correctly in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:24:28.554645Z",
     "iopub.status.busy": "2022-01-26T05:24:28.554070Z",
     "iopub.status.idle": "2022-01-26T05:24:30.542592Z",
     "shell.execute_reply": "2022-01-26T05:24:30.542046Z"
    },
    "id": "qbIMMkfmRHyC"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Files\\RL Playground\\PA2\\actor_critic_mc.ipynb Cell 17'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Files/RL%20Playground/PA2/actor_critic_mc.ipynb#ch0000016?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Files/RL%20Playground/PA2/actor_critic_mc.ipynb#ch0000016?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyvirtualdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m Display\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Files/RL%20Playground/PA2/actor_critic_mc.ipynb#ch0000016?line=7'>8</a>\u001b[0m display \u001b[39m=\u001b[39m Display(visible\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, size\u001b[39m=\u001b[39;49m(\u001b[39m400\u001b[39;49m, \u001b[39m300\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Files/RL%20Playground/PA2/actor_critic_mc.ipynb#ch0000016?line=8'>9</a>\u001b[0m display\u001b[39m.\u001b[39mstart()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/RL%20Playground/PA2/actor_critic_mc.ipynb#ch0000016?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender_episode\u001b[39m(env: gym\u001b[39m.\u001b[39mEnv, model: tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mModel, max_steps: \u001b[39mint\u001b[39m): \n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyvirtualdisplay\\display.py:54\u001b[0m, in \u001b[0;36mDisplay.__init__\u001b[1;34m(self, backend, visible, size, color_depth, bgcolor, use_xauth, retries, extra_args, manage_global_env, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/display.py?line=50'>51</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcls\u001b[39m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/display.py?line=51'>52</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munknown backend: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend)\n\u001b[1;32m---> <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/display.py?line=53'>54</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/display.py?line=54'>55</a>\u001b[0m     size\u001b[39m=\u001b[39msize,\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/display.py?line=55'>56</a>\u001b[0m     color_depth\u001b[39m=\u001b[39mcolor_depth,\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/display.py?line=56'>57</a>\u001b[0m     bgcolor\u001b[39m=\u001b[39mbgcolor,\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/display.py?line=57'>58</a>\u001b[0m     retries\u001b[39m=\u001b[39mretries,\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/display.py?line=58'>59</a>\u001b[0m     use_xauth\u001b[39m=\u001b[39muse_xauth,\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/display.py?line=59'>60</a>\u001b[0m     \u001b[39m# check_startup=check_startup,\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/display.py?line=60'>61</a>\u001b[0m     extra_args\u001b[39m=\u001b[39mextra_args,\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/display.py?line=61'>62</a>\u001b[0m     manage_global_env\u001b[39m=\u001b[39mmanage_global_env,\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/display.py?line=62'>63</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/display.py?line=63'>64</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyvirtualdisplay\\xvfb.py:44\u001b[0m, in \u001b[0;36mXvfbDisplay.__init__\u001b[1;34m(self, size, color_depth, bgcolor, use_xauth, fbdir, dpi, retries, extra_args, manage_global_env)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/xvfb.py?line=40'>41</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fbdir \u001b[39m=\u001b[39m fbdir\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/xvfb.py?line=41'>42</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dpi \u001b[39m=\u001b[39m dpi\n\u001b[1;32m---> <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/xvfb.py?line=43'>44</a>\u001b[0m AbstractDisplay\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/xvfb.py?line=44'>45</a>\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/xvfb.py?line=45'>46</a>\u001b[0m     PROGRAM,\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/xvfb.py?line=46'>47</a>\u001b[0m     use_xauth\u001b[39m=\u001b[39;49muse_xauth,\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/xvfb.py?line=47'>48</a>\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/xvfb.py?line=48'>49</a>\u001b[0m     extra_args\u001b[39m=\u001b[39;49mextra_args,\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/xvfb.py?line=49'>50</a>\u001b[0m     manage_global_env\u001b[39m=\u001b[39;49mmanage_global_env,\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/xvfb.py?line=50'>51</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyvirtualdisplay\\abstractdisplay.py:85\u001b[0m, in \u001b[0;36mAbstractDisplay.__init__\u001b[1;34m(self, program, use_xauth, retries, extra_args, manage_global_env)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/abstractdisplay.py?line=81'>82</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipe_wfd \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/abstractdisplay.py?line=82'>83</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retries_current \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/abstractdisplay.py?line=84'>85</a>\u001b[0m helptext \u001b[39m=\u001b[39m get_helptext(program)\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/abstractdisplay.py?line=85'>86</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_displayfd \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-displayfd\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m helptext\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/abstractdisplay.py?line=86'>87</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_displayfd:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyvirtualdisplay\\util.py:13\u001b[0m, in \u001b[0;36mget_helptext\u001b[1;34m(program)\u001b[0m\n\u001b[0;32m      <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/util.py?line=5'>6</a>\u001b[0m cmd \u001b[39m=\u001b[39m [program, \u001b[39m\"\u001b[39m\u001b[39m-help\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/util.py?line=7'>8</a>\u001b[0m \u001b[39m# py3.7+\u001b[39;00m\n\u001b[0;32m      <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/util.py?line=8'>9</a>\u001b[0m \u001b[39m# p = subprocess.run(cmd, capture_output=True)\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/util.py?line=9'>10</a>\u001b[0m \u001b[39m# stderr = p.stderr\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/util.py?line=10'>11</a>\u001b[0m \n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/util.py?line=11'>12</a>\u001b[0m \u001b[39m# py3.6 also\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/util.py?line=12'>13</a>\u001b[0m p \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/util.py?line=13'>14</a>\u001b[0m     cmd,\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/util.py?line=14'>15</a>\u001b[0m     stdout\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/util.py?line=15'>16</a>\u001b[0m     stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE,\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/util.py?line=16'>17</a>\u001b[0m     shell\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/util.py?line=17'>18</a>\u001b[0m )\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/util.py?line=18'>19</a>\u001b[0m _, stderr \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mcommunicate()\n\u001b[0;32m     <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/pyvirtualdisplay/util.py?line=20'>21</a>\u001b[0m helptext \u001b[39m=\u001b[39m stderr\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=946'>947</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=947'>948</a>\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=948'>949</a>\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=950'>951</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=951'>952</a>\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=952'>953</a>\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=953'>954</a>\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=954'>955</a>\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=955'>956</a>\u001b[0m                         errread, errwrite,\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=956'>957</a>\u001b[0m                         restore_signals,\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=957'>958</a>\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=958'>959</a>\u001b[0m                         start_new_session)\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=959'>960</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=960'>961</a>\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=961'>962</a>\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\subprocess.py:1420\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1417'>1418</a>\u001b[0m \u001b[39m# Start the process\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1418'>1419</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1419'>1420</a>\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1420'>1421</a>\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1421'>1422</a>\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1422'>1423</a>\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1423'>1424</a>\u001b[0m                              creationflags,\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1424'>1425</a>\u001b[0m                              env,\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1425'>1426</a>\u001b[0m                              cwd,\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1426'>1427</a>\u001b[0m                              startupinfo)\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1427'>1428</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1428'>1429</a>\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1429'>1430</a>\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1432'>1433</a>\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1433'>1434</a>\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1434'>1435</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1435'>1436</a>\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/subprocess.py?line=1436'>1437</a>\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "# Render an episode and save as a GIF file\n",
    "\n",
    "from IPython import display as ipythondisplay\n",
    "from PIL import Image\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "\n",
    "display = Display(visible=0, size=(400, 300))\n",
    "display.start()\n",
    "\n",
    "\n",
    "def render_episode(env: gym.Env, model: tf.keras.Model, max_steps: int): \n",
    "  screen = env.render(mode='rgb_array')\n",
    "  im = Image.fromarray(screen)\n",
    "\n",
    "  images = [im]\n",
    "  \n",
    "  state = tf.constant(env.reset(), dtype=tf.float32)\n",
    "  for i in range(1, max_steps + 1):\n",
    "    state = tf.expand_dims(state, 0)\n",
    "    action_probs, _ = model(state)\n",
    "    action = np.argmax(np.squeeze(action_probs))\n",
    "\n",
    "    state, _, done, _ = env.step(action)\n",
    "    state = tf.constant(state, dtype=tf.float32)\n",
    "\n",
    "    # Render screen every 10 steps\n",
    "    if i % 10 == 0:\n",
    "      screen = env.render(mode='rgb_array')\n",
    "      images.append(Image.fromarray(screen))\n",
    "  \n",
    "    if done:\n",
    "      break\n",
    "  \n",
    "  return images\n",
    "\n",
    "\n",
    "# Save GIF image\n",
    "images = render_episode(env, model, max_steps_per_episode)\n",
    "image_file = 'cartpole-v0.gif'\n",
    "# loop=0: loop forever, duration=1: play each frame for 1ms\n",
    "images[0].save(\n",
    "    image_file, save_all=True, append_images=images[1:], loop=0, duration=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-26T05:24:30.547219Z",
     "iopub.status.busy": "2022-01-26T05:24:30.546642Z",
     "iopub.status.idle": "2022-01-26T05:24:30.684160Z",
     "shell.execute_reply": "2022-01-26T05:24:30.684567Z"
    },
    "id": "TLd720SejKmf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/gif;base64,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\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnq9Hzo1Po6X"
   },
   "source": [
    "## Next steps\n",
    "\n",
    "This tutorial demonstrated how to implement the actor-critic method using Tensorflow.\n",
    "\n",
    "As a next step, you could try training a model on a different environment in OpenAI Gym. \n",
    "\n",
    "For additional information regarding actor-critic methods and the Cartpole-v0 problem, you may refer to the following resources:\n",
    "\n",
    "- [Actor Critic Method](https://hal.inria.fr/hal-00840470/document)\n",
    "- [Actor Critic Lecture (CAL)](https://www.youtube.com/watch?v=EKqxumCuAAY&list=PLkFD6_40KJIwhWJpGazJ9VSj9CFMkb79A&index=7&t=0s)\n",
    "- [Cartpole learning control problem \\[Barto, et al. 1983\\]](http://www.derongliu.org/adp/adp-cdrom/Barto1983.pdf) \n",
    "\n",
    "For more reinforcement learning examples in TensorFlow, you can check the following resources:\n",
    "- [Reinforcement learning code examples (keras.io)](https://keras.io/examples/rl/)\n",
    "- [TF-Agents reinforcement learning library](https://www.tensorflow.org/agents)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_jQ1tEQCxwRx"
   ],
   "name": "actor_critic.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
