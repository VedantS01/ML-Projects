{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "from math import floor\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "seed = 42\n",
    "rg = np.random.RandomState(seed)\n",
    "\n",
    "# Epsilon greedy\n",
    "def choose_action_epsilon(env,Q, state, hyper=0.1, rg=rg):\n",
    "    if not Q[int(state/(env.num_cols)), state%(env.num_cols)].any() or rg.rand() < hyper:\n",
    "        return rg.choice(Q.shape[-1])\n",
    "    else:\n",
    "        return np.argmax(Q[int(state/(env.num_cols)), state%(env.num_cols)])\n",
    "\n",
    "# Softmax\n",
    "def choose_action_softmax(env,Q, state,hyper=1, rg=rg):\n",
    "    return rg.choice(Q.shape[-1], p = softmax(Q[int(state/(env.num_cols)), state%(env.num_cols)] / hyper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = 12\n",
    "wind = True\n",
    "start_state = [0,4]\n",
    "p = 1.0\n",
    "chosenAction = choose_action_epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_alpha = 0.4\n",
    "opt_gamma = 0.7\n",
    "tol_alpha = 0.2\n",
    "tol_gamma = 0.2\n",
    "opt_epsilon = 1.\n",
    "tol_epsilon = 0.\n",
    "\n",
    "# hyper parameter set\n",
    "alphas = np.linspace(opt_alpha-tol_alpha,opt_alpha+tol_alpha,5)\n",
    "gammas = np.linspace(opt_gamma-tol_gamma,opt_gamma+tol_gamma,5)\n",
    "epsilons = np.linspace(opt_epsilon-tol_epsilon,opt_epsilon+tol_epsilon,1)\n",
    "episodes = 20000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SpXfJ6XXLtTe"
   },
   "outputs": [],
   "source": [
    "\n",
    "def row_col_to_seq(row_col, num_cols):  #Converts state number to row_column format\n",
    "    return row_col[:,0] * num_cols + row_col[:,1]\n",
    "\n",
    "def seq_to_col_row(seq, num_cols): #Converts row_column format to state number\n",
    "    r = floor(seq / num_cols)\n",
    "    c = seq - r * num_cols\n",
    "    return np.array([[r, c]])\n",
    "class GridWorld:\n",
    "    \"\"\"\n",
    "    Creates a gridworld object to pass to an RL algorithm.\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_rows : int\n",
    "        The number of rows in the gridworld.\n",
    "    num_cols : int\n",
    "        The number of cols in the gridworld.\n",
    "    start_state : numpy array of shape (1, 2), np.array([[row, col]])\n",
    "        The start state of the gridworld (can only be one start state)\n",
    "    goal_states : numpy arrany of shape (n, 2)\n",
    "        The goal states for the gridworld where n is the number of goal\n",
    "        states.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_rows, num_cols, start_state, goal_states, wind = False):\n",
    "        self.num_rows = num_rows\n",
    "        self.num_cols = num_cols\n",
    "        self.start_state = start_state\n",
    "        self.goal_states = goal_states\n",
    "        self.obs_states = None\n",
    "        self.bad_states = None\n",
    "        self.num_bad_states = 0\n",
    "        self.p_good_trans = None\n",
    "        self.bias = None\n",
    "        self.r_step = None\n",
    "        self.r_goal = None\n",
    "        self.r_dead = None\n",
    "        self.gamma = 1 # default is no discounting\n",
    "        self.wind = wind\n",
    "\n",
    "    def add_obstructions(self, obstructed_states=None, bad_states=None, restart_states=None):\n",
    "\n",
    "        self.obs_states = obstructed_states\n",
    "        self.bad_states = bad_states\n",
    "        if bad_states is not None:\n",
    "            self.num_bad_states = bad_states.shape[0]\n",
    "        else:\n",
    "            self.num_bad_states = 0\n",
    "        self.restart_states = restart_states\n",
    "        if restart_states is not None:\n",
    "            self.num_restart_states = restart_states.shape[0]\n",
    "        else:\n",
    "            self.num_restart_states = 0\n",
    "\n",
    "    def add_transition_probability(self, p_good_transition, bias):\n",
    "\n",
    "        self.p_good_trans = p_good_transition\n",
    "        self.bias = bias\n",
    "\n",
    "    def add_rewards(self, step_reward, goal_reward, bad_state_reward=None, restart_state_reward = None):\n",
    "\n",
    "        self.r_step = step_reward\n",
    "        self.r_goal = goal_reward\n",
    "        self.r_bad = bad_state_reward\n",
    "        self.r_restart = restart_state_reward\n",
    "\n",
    "\n",
    "    def create_gridworld(self):\n",
    "\n",
    "        self.num_actions = 4\n",
    "        self.num_states = self.num_cols * self.num_rows# +1\n",
    "        self.start_state_seq = row_col_to_seq(self.start_state, self.num_cols)\n",
    "        self.goal_states_seq = row_col_to_seq(self.goal_states, self.num_cols)\n",
    "\n",
    "        # rewards structure\n",
    "        self.R = self.r_step * np.ones((self.num_states, 1))\n",
    "        #self.R[self.num_states-1] = 0\n",
    "        self.R[self.goal_states_seq] = self.r_goal\n",
    "        \n",
    "        for i in range(self.num_bad_states):\n",
    "            if self.r_bad is None:\n",
    "                raise Exception(\"Bad state specified but no reward is given\")\n",
    "            bad_state = row_col_to_seq(self.bad_states[i,:].reshape(1,-1), self.num_cols)\n",
    "            #print(\"bad states\", bad_state)\n",
    "            self.R[bad_state, :] = self.r_bad\n",
    "        for i in range(self.num_restart_states):\n",
    "            if self.r_restart is None:\n",
    "                raise Exception(\"Restart state specified but no reward is given\")\n",
    "            restart_state = row_col_to_seq(self.restart_states[i,:].reshape(1,-1), self.num_cols)\n",
    "            #print(\"restart_state\", restart_state)\n",
    "            self.R[restart_state, :] = self.r_restart\n",
    "\n",
    "        # probability model\n",
    "        if self.p_good_trans == None:\n",
    "            raise Exception(\"Must assign probability and bias terms via the add_transition_probability method.\")\n",
    "\n",
    "        self.P = np.zeros((self.num_states,self.num_states,self.num_actions))\n",
    "        for action in range(self.num_actions):\n",
    "            for state in range(self.num_states):\n",
    "\n",
    "\n",
    "                # check if the state is the goal state or an obstructed state - transition to end\n",
    "                row_col = seq_to_col_row(state, self.num_cols)\n",
    "                if self.obs_states is not None:\n",
    "                    end_states = np.vstack((self.obs_states, self.goal_states))\n",
    "                else:\n",
    "                    end_states = self.goal_states\n",
    "\n",
    "                if any(np.sum(np.abs(end_states-row_col), 1) == 0):\n",
    "                    self.P[state, state, action] = 1\n",
    "\n",
    "                # else consider stochastic effects of action\n",
    "                else:\n",
    "                    for dir in range(-1,2,1):\n",
    "                        \n",
    "                        direction = self._get_direction(action, dir)\n",
    "                        next_state = self._get_state(state, direction)\n",
    "                        if dir == 0:\n",
    "                            prob = self.p_good_trans\n",
    "                        elif dir == -1:\n",
    "                            prob = (1 - self.p_good_trans)*(self.bias)\n",
    "                        elif dir == 1:\n",
    "                            prob = (1 - self.p_good_trans)*(1-self.bias)\n",
    "\n",
    "                        self.P[state, next_state, action] += prob\n",
    "\n",
    "                # make restart states transition back to the start state with\n",
    "                # probability 1\n",
    "                if self.restart_states is not None:\n",
    "                    if any(np.sum(np.abs(self.restart_states-row_col),1)==0):\n",
    "                        next_state = row_col_to_seq(self.start_state, self.num_cols)\n",
    "                        self.P[state,:,:] = 0\n",
    "                        self.P[state,next_state,:] = 1\n",
    "        return self\n",
    "\n",
    "    def _get_direction(self, action, direction):\n",
    "\n",
    "        left = [2,3,1,0]\n",
    "        right = [3,2,0,1]\n",
    "        if direction == 0:\n",
    "            new_direction = action\n",
    "        elif direction == -1:\n",
    "            new_direction = left[action]\n",
    "        elif direction == 1:\n",
    "            new_direction = right[action]\n",
    "        else:\n",
    "            raise Exception(\"getDir received an unspecified case\")\n",
    "        return new_direction\n",
    "\n",
    "    def _get_state(self, state, direction):\n",
    "\n",
    "        row_change = [-1,1,0,0]\n",
    "        col_change = [0,0,-1,1]\n",
    "        row_col = seq_to_col_row(state, self.num_cols)\n",
    "        row_col[0,0] += row_change[direction]\n",
    "        row_col[0,1] += col_change[direction]\n",
    "\n",
    "        # check for invalid states\n",
    "        if self.obs_states is not None:\n",
    "            if (np.any(row_col < 0) or\n",
    "                np.any(row_col[:,0] > self.num_rows-1) or\n",
    "                np.any(row_col[:,1] > self.num_cols-1) or\n",
    "                np.any(np.sum(abs(self.obs_states - row_col), 1)==0)):\n",
    "                next_state = state\n",
    "            else:\n",
    "                next_state = row_col_to_seq(row_col, self.num_cols)[0]\n",
    "        else:\n",
    "            if (np.any(row_col < 0) or\n",
    "                np.any(row_col[:,0] > self.num_rows-1) or\n",
    "                np.any(row_col[:,1] > self.num_cols-1)):\n",
    "                next_state = state\n",
    "            else:\n",
    "                next_state = row_col_to_seq(row_col, self.num_cols)[0]\n",
    "\n",
    "        return next_state\n",
    "\n",
    "    def reset(self):\n",
    "      return int(self.start_state_seq)\n",
    "      \n",
    "    def step(self, state, action):\n",
    "        p, r = 0, np.random.random()\n",
    "        for next_state in range(self.num_states):\n",
    "            \n",
    "            p += self.P[state, next_state, action]\n",
    "            \n",
    "            if r <= p:\n",
    "                break\n",
    "\n",
    "        if(self.wind and np.random.random() < 0.4):\n",
    "\n",
    "          arr = self.P[next_state, :, 3]\n",
    "          next_next = np.where(arr == np.amax(arr))\n",
    "          next_next = next_next[0][0]\n",
    "          return next_next, self.R[next_next]\n",
    "        else:\n",
    "          return next_state, self.R[next_state]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BqE09JUiL1B8"
   },
   "outputs": [],
   "source": [
    "# # specify world parameters\n",
    "# num_cols = 10\n",
    "# num_rows = 10\n",
    "# obstructions = np.array([[0,7],[1,1],[1,2],[1,3],[1,7],[2,1],[2,3],\n",
    "#                          [2,7],[3,1],[3,3],[3,5],[4,3],[4,5],[4,7],\n",
    "#                          [5,3],[5,7],[5,9],[6,3],[6,9],[7,1],[7,6],\n",
    "#                          [7,7],[7,8],[7,9],[8,1],[8,5],[8,6],[9,1]])\n",
    "# bad_states = np.array([[1,9],[4,2],[4,4],[7,5],[9,9]])\n",
    "# restart_states = np.array([[3,7],[8,2]])\n",
    "# start_state = np.array([[3,6]])\n",
    "# goal_states = np.array([[0,9],[2,2],[8,7]])\n",
    "\n",
    "# # create model\n",
    "# gw = GridWorld(num_rows=num_rows,\n",
    "#                num_cols=num_cols,\n",
    "#                start_state=start_state,\n",
    "#                goal_states=goal_states, wind = False)\n",
    "# gw.add_obstructions(obstructed_states=obstructions,\n",
    "#                     bad_states=bad_states,\n",
    "#                     restart_states=restart_states)\n",
    "# gw.add_rewards(step_reward=-1,\n",
    "#                goal_reward=10,\n",
    "#                bad_state_reward=-6,\n",
    "#                restart_state_reward=-100)\n",
    "# gw.add_transition_probability(p_good_transition=0.7,\n",
    "#                               bias=0.5)\n",
    "# env = gw.create_gridworld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UdRce8oMZNb",
    "outputId": "ee3858e1-e109-42e6-80eb-336702f708e3"
   },
   "outputs": [],
   "source": [
    "# print(\"Number of actions\", env.num_actions) #0 -> UP, 1-> DOWN, 2 -> LEFT, 3-> RIGHT\n",
    "# print(\"Number of states\", env.num_states)\n",
    "# print(\"start state\", env.start_state_seq)\n",
    "# print(\"goal state(s)\", env.goal_states_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "UP = 1\n",
    "DOWN = 0\n",
    "LEFT = 2\n",
    "RIGHT = 3\n",
    "def plot_Q(Q, message = \"Q plot\", save_file=None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.title(message)\n",
    "    plt.pcolor(Q.max(-1), edgecolors='k', linewidths=2)\n",
    "    plt.colorbar()\n",
    "    def x_direct(a):\n",
    "        if a in [UP, DOWN]:\n",
    "            return 0\n",
    "        return 1 if a == RIGHT else -1\n",
    "    def y_direct(a):\n",
    "        if a in [RIGHT, LEFT]:\n",
    "            return 0\n",
    "        return 1 if a == UP else -1\n",
    "    policy = Q.argmax(-1)\n",
    "    policyx = np.vectorize(x_direct)(policy)\n",
    "    policyy = np.vectorize(y_direct)(policy)\n",
    "    idx = np.indices(policy.shape)\n",
    "    plt.quiver(idx[1].ravel()+0.5, idx[0].ravel()+0.5, policyx.ravel(), policyy.ravel(), pivot=\"middle\", color='red')\n",
    "    if(save_file != None):\n",
    "        plt.savefig(save_file)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    # return fig\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def sarsa(env,Q,gamma,alpha,epsilon,choose_action,plot_heat = False,max_timesteps=100) :\n",
    "  episode_rewards = []\n",
    "  state_visit_count = np.zeros((env.num_rows, env.num_cols))\n",
    "  steps_to_completion = []\n",
    "  steps = 0\n",
    "  for steps in tqdm(range(episodes)):\n",
    "    timesteps=0\n",
    "    env.reset()\n",
    "    current_state = env.start_state_seq[0]\n",
    "    current_action = choose_action(env,Q,current_state,hyper=epsilon)\n",
    "    rewards = []\n",
    "    tot_reward = 0 \n",
    "    while timesteps<max_timesteps :\n",
    "      timesteps+=1\n",
    "      next_state,reward = env.step(current_state,current_action)\n",
    "      next_action = choose_action(env,Q,next_state, hyper=epsilon)\n",
    "      # best next action\n",
    "#       best_next_action = np.argmax(Q[next_state//env.num_rows,next_state%env.num_cols])\n",
    "      Q[int(current_state/(env.num_cols)), current_state%(env.num_cols), current_action] += alpha*(reward[0] + gamma*Q[int(next_state/(env.num_cols)), next_state%(env.num_cols), next_action] - Q[int(current_state/(env.num_cols)), current_state%(env.num_cols), current_action])\n",
    "      rewards.append(reward[0])\n",
    "      tot_reward = tot_reward + reward[0]\n",
    "      # print(reward)\n",
    "      if reward == env.r_goal :\n",
    "        break\n",
    "      # print(current_state)\n",
    "      current_state = next_state\n",
    "      current_action = next_action\n",
    "      state_visit_count[int(current_state/(env.num_cols)), current_state%(env.num_cols)]+=1\n",
    "    episode_rewards.append(tot_reward)\n",
    "    steps_to_completion.append(timesteps)\n",
    "\n",
    "    if (steps+1)%10 == 0 and plot_heat:\n",
    "      clear_output(wait=True)\n",
    "      plot_Q(Q, message = \"Episode %d: Reward: %f, Steps: %.2f, Qmax: %.2f, Qmin: %.2f\"%(steps+1, np.mean(episode_rewards[steps-10+1:steps]),\n",
    "                                                                           np.mean(steps_to_completion[steps-10+1:steps]),\n",
    "                                                                           Q.max(), Q.min()))\n",
    "  return Q, episode_rewards, steps_to_completion,state_visit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_Q(env,Q, max_timesteps=100) :\n",
    "    episode_rewards = []\n",
    "    steps_to_completion = []\n",
    "    steps = 0\n",
    "    episodes = 100\n",
    "    for steps in tqdm(range(episodes)):\n",
    "        timesteps=0\n",
    "        env.reset()\n",
    "        current_state = env.start_state_seq[0]\n",
    "        current_action = np.argmax(Q[int(current_state/(env.num_cols)), current_state%(env.num_cols)])\n",
    "        rewards = []\n",
    "        tot_reward = 0 \n",
    "        while timesteps<max_timesteps :\n",
    "            timesteps+=1\n",
    "            next_state,reward = env.step(current_state,current_action)\n",
    "            next_action = np.argmax(Q[int(next_state/(env.num_cols)), next_state%(env.num_cols)])\n",
    "\n",
    "            rewards.append(reward[0])\n",
    "            tot_reward = tot_reward + reward[0]\n",
    "            # print(reward)\n",
    "            if reward == env.r_goal :\n",
    "                break\n",
    "            # print(current_state)\n",
    "            current_state = next_state\n",
    "            current_action = next_action\n",
    "        episode_rewards.append(tot_reward)\n",
    "        steps_to_completion.append(timesteps)\n",
    "\n",
    "    return np.mean(episode_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify world parameters\n",
    "num_cols = 10\n",
    "num_rows = 10\n",
    "obstructions = np.array([[0,7],[1,1],[1,2],[1,3],[1,7],[2,1],[2,3],\n",
    "                         [2,7],[3,1],[3,3],[3,5],[4,3],[4,5],[4,7],\n",
    "                         [5,3],[5,7],[5,9],[6,3],[6,9],[7,1],[7,6],\n",
    "                         [7,7],[7,8],[7,9],[8,1],[8,5],[8,6],[9,1]])\n",
    "bad_states = np.array([[1,9],[4,2],[4,4],[7,5],[9,9]])\n",
    "restart_states = np.array([[3,7],[8,2]])\n",
    "start_state = np.array([start_state])\n",
    "goal_states = np.array([[0,9],[2,2],[8,7]])\n",
    "# create model\n",
    "gw = GridWorld(num_rows=num_rows,\n",
    "               num_cols=num_cols,\n",
    "               start_state=start_state,\n",
    "               goal_states=goal_states, wind = wind)\n",
    "gw.add_obstructions(obstructed_states=obstructions,\n",
    "                    bad_states=bad_states,\n",
    "                    restart_states=restart_states)\n",
    "gw.add_rewards(step_reward=-1,\n",
    "               goal_reward=10,\n",
    "               bad_state_reward=-6,\n",
    "               restart_state_reward=-100)\n",
    "gw.add_transition_probability(p_good_transition=p,\n",
    "                              bias=0.5)\n",
    "env = gw.create_gridworld()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [04:33<00:00, 73.12it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 280.90it/s]\n",
      "100%|██████████| 20000/20000 [04:24<00:00, 75.67it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 429.19it/s]\n",
      "100%|██████████| 20000/20000 [04:28<00:00, 74.62it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 293.26it/s]\n",
      "100%|██████████| 20000/20000 [04:33<00:00, 73.24it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1923.11it/s]\n",
      "100%|██████████| 20000/20000 [03:56<00:00, 84.65it/s] \n",
      "100%|██████████| 100/100 [00:00<00:00, 2272.51it/s]\n",
      "100%|██████████| 20000/20000 [04:29<00:00, 74.17it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 364.96it/s]\n",
      "100%|██████████| 20000/20000 [04:31<00:00, 73.64it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 341.30it/s]\n",
      "100%|██████████| 20000/20000 [04:30<00:00, 74.07it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1639.35it/s]\n",
      "100%|██████████| 20000/20000 [04:37<00:00, 72.03it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2083.45it/s]\n",
      "100%|██████████| 20000/20000 [03:53<00:00, 85.66it/s] \n",
      "100%|██████████| 100/100 [00:00<00:00, 1923.11it/s]\n",
      "100%|██████████| 20000/20000 [04:52<00:00, 68.37it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 408.17it/s]\n",
      "100%|██████████| 20000/20000 [04:10<00:00, 79.89it/s] \n",
      "100%|██████████| 100/100 [00:00<00:00, 414.94it/s]\n",
      "100%|██████████| 20000/20000 [04:24<00:00, 75.66it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1754.39it/s]\n",
      "100%|██████████| 20000/20000 [03:52<00:00, 85.90it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 442.48it/s]\n",
      "100%|██████████| 20000/20000 [03:06<00:00, 107.01it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2325.57it/s]\n",
      "100%|██████████| 20000/20000 [03:53<00:00, 85.74it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 400.00it/s]\n",
      "100%|██████████| 20000/20000 [03:46<00:00, 88.36it/s] \n",
      "100%|██████████| 100/100 [00:00<00:00, 411.53it/s]\n",
      "100%|██████████| 20000/20000 [03:33<00:00, 93.81it/s] \n",
      "100%|██████████| 100/100 [00:00<00:00, 395.26it/s]\n",
      "100%|██████████| 20000/20000 [03:46<00:00, 88.29it/s] \n",
      "100%|██████████| 100/100 [00:00<00:00, 465.11it/s]\n",
      "100%|██████████| 20000/20000 [03:22<00:00, 98.54it/s] \n",
      "100%|██████████| 100/100 [00:00<00:00, 387.60it/s]\n",
      "100%|██████████| 20000/20000 [03:57<00:00, 84.26it/s] \n",
      "100%|██████████| 100/100 [00:00<00:00, 555.56it/s]\n",
      "100%|██████████| 20000/20000 [03:34<00:00, 93.36it/s] \n",
      "100%|██████████| 100/100 [00:00<00:00, 386.10it/s]\n",
      "100%|██████████| 20000/20000 [03:33<00:00, 93.73it/s] \n",
      "100%|██████████| 100/100 [00:00<00:00, 500.00it/s]\n",
      "100%|██████████| 20000/20000 [03:10<00:00, 105.19it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 704.23it/s]\n",
      "100%|██████████| 20000/20000 [02:36<00:00, 127.78it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2563.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 0.7999999999999999 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tune hyperparameters\n",
    "from math import inf\n",
    "seed = 42\n",
    "max_valuation = -inf\n",
    "for alpha in alphas:\n",
    "    for gamma in gammas:\n",
    "        for epsilon in epsilons:\n",
    "            Q = np.zeros((env.num_rows, env.num_cols, env.num_actions))\n",
    "            rg = np.random.RandomState(seed)\n",
    "            if(conf % 2 == 0):\n",
    "                Q, rewards, steps, _ = sarsa(env, Q,gamma,alpha,epsilon,choose_action = choose_action_softmax)\n",
    "            else:\n",
    "                Q, rewards, steps, _ = sarsa(env, Q,gamma,alpha,epsilon,choose_action = choose_action_epsilon)\n",
    "            valuation = eval_Q(env,Q)\n",
    "            if(valuation >= max_valuation):\n",
    "                opt_alpha = alpha\n",
    "                opt_gamma = gamma\n",
    "                opt_epsilon = epsilon\n",
    "                max_valuation = valuation\n",
    "            \n",
    "print(opt_alpha,opt_gamma,opt_epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_avgs, reward_avgs, steps_avgs = [], [], []\n",
    "num_expts = 3\n",
    "\n",
    "alpha = opt_alpha = 0.2\n",
    "gamma = opt_gamma = 0.8\n",
    "# epsilon = opt_epsilon\n",
    "episodes = 20000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(num_expts):\n",
    "    print(\"Experiment: %d\"%(i+1))\n",
    "    Q = np.zeros((env.num_rows, env.num_cols, env.num_actions))\n",
    "    rg = np.random.RandomState(i)\n",
    "    Q, rewards, steps, _ = sarsa(env, Q,gamma,alpha,1,choose_action = choose_action_softmax)\n",
    "    Q_avgs.append(Q.copy())\n",
    "    reward_avgs.append(rewards)\n",
    "    steps_avgs.append(steps)\n",
    "    \n",
    "conv_rewards = np.mean(np.average(reward_avgs,axis=0)[episodes-10:episodes])\n",
    "conv_steps = np.mean(np.average(steps_avgs,axis=0)[episodes-10:episodes])\n",
    "print(\"Convergence of rewards approx. \", conv_rewards)\n",
    "print(\"Convergence of time steps approx. \", conv_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vedant\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:495: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "C:\\Users\\Vedant\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (20000,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Files\\RL Playground\\sarsa\\PA1_conf12.ipynb Cell 14'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/RL%20Playground/sarsa/PA1_conf12.ipynb#ch0000012?line=9'>10</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mEpisode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/RL%20Playground/sarsa/PA1_conf12.ipynb#ch0000012?line=10'>11</a>\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mNumber of steps to Goal\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Files/RL%20Playground/sarsa/PA1_conf12.ipynb#ch0000012?line=11'>12</a>\u001b[0m plt\u001b[39m.\u001b[39;49mplot(np\u001b[39m.\u001b[39;49marange(episodes),np\u001b[39m.\u001b[39;49maverage(steps_avgs, \u001b[39m0\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/RL%20Playground/sarsa/PA1_conf12.ipynb#ch0000012?line=12'>13</a>\u001b[0m \u001b[39m# plt.show()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/RL%20Playground/sarsa/PA1_conf12.ipynb#ch0000012?line=13'>14</a>\u001b[0m plt\u001b[39m.\u001b[39msavefig(\u001b[39m'\u001b[39m\u001b[39mconf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(conf)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/steps-vs-episodes.jpeg\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\pyplot.py:2757\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/pyplot.py?line=2754'>2755</a>\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/pyplot.py?line=2755'>2756</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/pyplot.py?line=2756'>2757</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39mplot(\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/pyplot.py?line=2757'>2758</a>\u001b[0m         \u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39mscalex, scaley\u001b[39m=\u001b[39mscaley,\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/pyplot.py?line=2758'>2759</a>\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_axes.py?line=1389'>1390</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_axes.py?line=1390'>1391</a>\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_axes.py?line=1391'>1392</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_axes.py?line=1628'>1629</a>\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_axes.py?line=1629'>1630</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_axes.py?line=1630'>1631</a>\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[1;32m-> <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_axes.py?line=1631'>1632</a>\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_axes.py?line=1632'>1633</a>\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m   <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_axes.py?line=1633'>1634</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_base.py?line=309'>310</a>\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_base.py?line=310'>311</a>\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_base.py?line=311'>312</a>\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(this, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_base.py:498\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_base.py?line=494'>495</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39myaxis\u001b[39m.\u001b[39mupdate_units(y)\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_base.py?line=496'>497</a>\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_base.py?line=497'>498</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y must have same first dimension, but \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_base.py?line=498'>499</a>\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhave shapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_base.py?line=499'>500</a>\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_base.py?line=500'>501</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y can be no greater than 2D, but have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Vedant/AppData/Local/Programs/Python/Python39/lib/site-packages/matplotlib/axes/_base.py?line=501'>502</a>\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20000,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    os.mkdir('conf'+str(conf))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "plt.style.use('seaborn-poster')\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Number of steps to Goal')\n",
    "plt.plot(np.arange(episodes),np.average(steps_avgs, 0))\n",
    "# plt.show()\n",
    "plt.savefig('conf'+str(conf)+'/steps-vs-episodes.jpeg')\n",
    "plt.close()\n",
    "plt.style.use('seaborn-poster')\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.plot(np.arange(episodes),np.average(reward_avgs, 0))\n",
    "# plt.show()\n",
    "plt.savefig('conf'+str(conf)+'/rewards-vs-episodes.jpeg')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [03:32<00:00, 94.21it/s] \n"
     ]
    }
   ],
   "source": [
    "alpha = opt_alpha\n",
    "gamma = opt_gamma\n",
    "epsilon = opt_epsilon\n",
    "episodes = 20000\n",
    "\n",
    "Q = np.zeros((env.num_rows, env.num_cols, env.num_actions))\n",
    "rg = np.random.RandomState(seed)\n",
    "Q, rewards, steps, state_visit_count = sarsa(env, Q,gamma,alpha,epsilon,choose_action = choose_action_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plot = sns.heatmap(state_visit_count)\n",
    "plot.invert_yaxis()\n",
    "fig = plot.get_figure()\n",
    "fig.savefig('conf'+str(conf)+'/heatmap-state-visit-count.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Q(Q, save_file='conf'+str(conf)+'/heatmap-policy.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 2941.31it/s]\n"
     ]
    }
   ],
   "source": [
    "valuation = eval_Q(env,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_rewards' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Files\\RL Playground\\sarsa\\PA1_conf12.ipynb Cell 19'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/RL%20Playground/sarsa/PA1_conf12.ipynb#ch0000017?line=10'>11</a>\u001b[0m f\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39mopt_epsilon = \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(opt_epsilon)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/RL%20Playground/sarsa/PA1_conf12.ipynb#ch0000017?line=11'>12</a>\u001b[0m f\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mconvergence: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Files/RL%20Playground/sarsa/PA1_conf12.ipynb#ch0000017?line=12'>13</a>\u001b[0m f\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39mrewards = \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(conv_rewards)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/RL%20Playground/sarsa/PA1_conf12.ipynb#ch0000017?line=13'>14</a>\u001b[0m f\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39msteps = \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(conv_steps)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Files/RL%20Playground/sarsa/PA1_conf12.ipynb#ch0000017?line=14'>15</a>\u001b[0m f\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mevaluation: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(valuation)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'conv_rewards' is not defined"
     ]
    }
   ],
   "source": [
    "# conf = 17\n",
    "\n",
    "with open('conf'+str(conf)+'/hyperparameter-tuning-results.txt', 'w') as f:\n",
    "    f.write('conf '+ str(conf) + '\\n')\n",
    "    f.write('wind = ' + str(wind) + '\\n')\n",
    "    f.write('start state = ' + str(start_state) + '\\n')\n",
    "    f.write('p = ' + str(p) + '\\n')\n",
    "    f.write('strategy = e_greedy\\n\\n')\n",
    "    f.write('opt_alpha = ' + str(opt_alpha) + '\\n')\n",
    "    f.write('opt_gamma = ' + str(opt_gamma)+'\\n')\n",
    "    f.write('opt_epsilon = ' + str(opt_epsilon)+'\\n')\n",
    "    f.write('\\nconvergence: '+'\\n')\n",
    "    f.write('rewards = ' + str(conv_rewards)+'\\n')\n",
    "    f.write('steps = ' + str(conv_steps)+'\\n')\n",
    "    f.write('\\nevaluation: ' + str(valuation)+'\\n')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PA1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
