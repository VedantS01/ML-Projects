{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "from math import floor\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "seed = 42\n",
    "rg = np.random.RandomState(seed)\n",
    "\n",
    "# Epsilon greedy\n",
    "def choose_action_epsilon(env,Q, state, hyper=0.1, rg=rg):\n",
    "    if not Q[int(state/(env.num_cols)), state%(env.num_cols)].any() or rg.rand() < hyper:\n",
    "        return rg.choice(Q.shape[-1])\n",
    "    else:\n",
    "        return np.argmax(Q[int(state/(env.num_cols)), state%(env.num_cols)])\n",
    "\n",
    "# Softmax\n",
    "def choose_action_softmax(env,Q, state,hyper=1, rg=rg):\n",
    "    return rg.choice(Q.shape[-1], p = softmax(Q[int(state/(env.num_cols)), state%(env.num_cols)] / hyper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = 9\n",
    "# os.mkdir(\"conf\"+str(conf))\n",
    "wind = True\n",
    "start_state = [0,4]\n",
    "p = 1.0\n",
    "chosenAction = choose_action_epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_alpha = 0.4\n",
    "opt_gamma = 0.7\n",
    "tol_alpha = 0.2\n",
    "tol_gamma = 0.2\n",
    "opt_epsilon = 0.\n",
    "tol_epsilon = 0.\n",
    "\n",
    "# hyper parameter set\n",
    "alphas = np.linspace(opt_alpha-tol_alpha,opt_alpha+tol_alpha,5)\n",
    "gammas = np.linspace(opt_gamma-tol_gamma,opt_gamma+tol_gamma,5)\n",
    "epsilons = [0,0.01,0.1]\n",
    "episodes = 20000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SpXfJ6XXLtTe"
   },
   "outputs": [],
   "source": [
    "\n",
    "def row_col_to_seq(row_col, num_cols):  #Converts state number to row_column format\n",
    "    return row_col[:,0] * num_cols + row_col[:,1]\n",
    "\n",
    "def seq_to_col_row(seq, num_cols): #Converts row_column format to state number\n",
    "    r = floor(seq / num_cols)\n",
    "    c = seq - r * num_cols\n",
    "    return np.array([[r, c]])\n",
    "class GridWorld:\n",
    "    \"\"\"\n",
    "    Creates a gridworld object to pass to an RL algorithm.\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_rows : int\n",
    "        The number of rows in the gridworld.\n",
    "    num_cols : int\n",
    "        The number of cols in the gridworld.\n",
    "    start_state : numpy array of shape (1, 2), np.array([[row, col]])\n",
    "        The start state of the gridworld (can only be one start state)\n",
    "    goal_states : numpy arrany of shape (n, 2)\n",
    "        The goal states for the gridworld where n is the number of goal\n",
    "        states.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_rows, num_cols, start_state, goal_states, wind = False):\n",
    "        self.num_rows = num_rows\n",
    "        self.num_cols = num_cols\n",
    "        self.start_state = start_state\n",
    "        self.goal_states = goal_states\n",
    "        self.obs_states = None\n",
    "        self.bad_states = None\n",
    "        self.num_bad_states = 0\n",
    "        self.p_good_trans = None\n",
    "        self.bias = None\n",
    "        self.r_step = None\n",
    "        self.r_goal = None\n",
    "        self.r_dead = None\n",
    "        self.gamma = 1 # default is no discounting\n",
    "        self.wind = wind\n",
    "\n",
    "    def add_obstructions(self, obstructed_states=None, bad_states=None, restart_states=None):\n",
    "\n",
    "        self.obs_states = obstructed_states\n",
    "        self.bad_states = bad_states\n",
    "        if bad_states is not None:\n",
    "            self.num_bad_states = bad_states.shape[0]\n",
    "        else:\n",
    "            self.num_bad_states = 0\n",
    "        self.restart_states = restart_states\n",
    "        if restart_states is not None:\n",
    "            self.num_restart_states = restart_states.shape[0]\n",
    "        else:\n",
    "            self.num_restart_states = 0\n",
    "\n",
    "    def add_transition_probability(self, p_good_transition, bias):\n",
    "\n",
    "        self.p_good_trans = p_good_transition\n",
    "        self.bias = bias\n",
    "\n",
    "    def add_rewards(self, step_reward, goal_reward, bad_state_reward=None, restart_state_reward = None):\n",
    "\n",
    "        self.r_step = step_reward\n",
    "        self.r_goal = goal_reward\n",
    "        self.r_bad = bad_state_reward\n",
    "        self.r_restart = restart_state_reward\n",
    "\n",
    "\n",
    "    def create_gridworld(self):\n",
    "\n",
    "        self.num_actions = 4\n",
    "        self.num_states = self.num_cols * self.num_rows# +1\n",
    "        self.start_state_seq = row_col_to_seq(self.start_state, self.num_cols)\n",
    "        self.goal_states_seq = row_col_to_seq(self.goal_states, self.num_cols)\n",
    "\n",
    "        # rewards structure\n",
    "        self.R = self.r_step * np.ones((self.num_states, 1))\n",
    "        #self.R[self.num_states-1] = 0\n",
    "        self.R[self.goal_states_seq] = self.r_goal\n",
    "        \n",
    "        for i in range(self.num_bad_states):\n",
    "            if self.r_bad is None:\n",
    "                raise Exception(\"Bad state specified but no reward is given\")\n",
    "            bad_state = row_col_to_seq(self.bad_states[i,:].reshape(1,-1), self.num_cols)\n",
    "            #print(\"bad states\", bad_state)\n",
    "            self.R[bad_state, :] = self.r_bad\n",
    "        for i in range(self.num_restart_states):\n",
    "            if self.r_restart is None:\n",
    "                raise Exception(\"Restart state specified but no reward is given\")\n",
    "            restart_state = row_col_to_seq(self.restart_states[i,:].reshape(1,-1), self.num_cols)\n",
    "            #print(\"restart_state\", restart_state)\n",
    "            self.R[restart_state, :] = self.r_restart\n",
    "\n",
    "        # probability model\n",
    "        if self.p_good_trans == None:\n",
    "            raise Exception(\"Must assign probability and bias terms via the add_transition_probability method.\")\n",
    "\n",
    "        self.P = np.zeros((self.num_states,self.num_states,self.num_actions))\n",
    "        for action in range(self.num_actions):\n",
    "            for state in range(self.num_states):\n",
    "\n",
    "\n",
    "                # check if the state is the goal state or an obstructed state - transition to end\n",
    "                row_col = seq_to_col_row(state, self.num_cols)\n",
    "                if self.obs_states is not None:\n",
    "                    end_states = np.vstack((self.obs_states, self.goal_states))\n",
    "                else:\n",
    "                    end_states = self.goal_states\n",
    "\n",
    "                if any(np.sum(np.abs(end_states-row_col), 1) == 0):\n",
    "                    self.P[state, state, action] = 1\n",
    "\n",
    "                # else consider stochastic effects of action\n",
    "                else:\n",
    "                    for dir in range(-1,2,1):\n",
    "                        \n",
    "                        direction = self._get_direction(action, dir)\n",
    "                        next_state = self._get_state(state, direction)\n",
    "                        if dir == 0:\n",
    "                            prob = self.p_good_trans\n",
    "                        elif dir == -1:\n",
    "                            prob = (1 - self.p_good_trans)*(self.bias)\n",
    "                        elif dir == 1:\n",
    "                            prob = (1 - self.p_good_trans)*(1-self.bias)\n",
    "\n",
    "                        self.P[state, next_state, action] += prob\n",
    "\n",
    "                # make restart states transition back to the start state with\n",
    "                # probability 1\n",
    "                if self.restart_states is not None:\n",
    "                    if any(np.sum(np.abs(self.restart_states-row_col),1)==0):\n",
    "                        next_state = row_col_to_seq(self.start_state, self.num_cols)\n",
    "                        self.P[state,:,:] = 0\n",
    "                        self.P[state,next_state,:] = 1\n",
    "        return self\n",
    "\n",
    "    def _get_direction(self, action, direction):\n",
    "\n",
    "        left = [2,3,1,0]\n",
    "        right = [3,2,0,1]\n",
    "        if direction == 0:\n",
    "            new_direction = action\n",
    "        elif direction == -1:\n",
    "            new_direction = left[action]\n",
    "        elif direction == 1:\n",
    "            new_direction = right[action]\n",
    "        else:\n",
    "            raise Exception(\"getDir received an unspecified case\")\n",
    "        return new_direction\n",
    "\n",
    "    def _get_state(self, state, direction):\n",
    "\n",
    "        row_change = [-1,1,0,0]\n",
    "        col_change = [0,0,-1,1]\n",
    "        row_col = seq_to_col_row(state, self.num_cols)\n",
    "        row_col[0,0] += row_change[direction]\n",
    "        row_col[0,1] += col_change[direction]\n",
    "\n",
    "        # check for invalid states\n",
    "        if self.obs_states is not None:\n",
    "            if (np.any(row_col < 0) or\n",
    "                np.any(row_col[:,0] > self.num_rows-1) or\n",
    "                np.any(row_col[:,1] > self.num_cols-1) or\n",
    "                np.any(np.sum(abs(self.obs_states - row_col), 1)==0)):\n",
    "                next_state = state\n",
    "            else:\n",
    "                next_state = row_col_to_seq(row_col, self.num_cols)[0]\n",
    "        else:\n",
    "            if (np.any(row_col < 0) or\n",
    "                np.any(row_col[:,0] > self.num_rows-1) or\n",
    "                np.any(row_col[:,1] > self.num_cols-1)):\n",
    "                next_state = state\n",
    "            else:\n",
    "                next_state = row_col_to_seq(row_col, self.num_cols)[0]\n",
    "\n",
    "        return next_state\n",
    "\n",
    "    def reset(self):\n",
    "      return int(self.start_state_seq)\n",
    "      \n",
    "    def step(self, state, action):\n",
    "        p, r = 0, np.random.random()\n",
    "        for next_state in range(self.num_states):\n",
    "            \n",
    "            p += self.P[state, next_state, action]\n",
    "            \n",
    "            if r <= p:\n",
    "                break\n",
    "\n",
    "        if(self.wind and np.random.random() < 0.4):\n",
    "\n",
    "          arr = self.P[next_state, :, 3]\n",
    "          next_next = np.where(arr == np.amax(arr))\n",
    "          next_next = next_next[0][0]\n",
    "          return next_next, self.R[next_next]\n",
    "        else:\n",
    "          return next_state, self.R[next_state]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BqE09JUiL1B8"
   },
   "outputs": [],
   "source": [
    "# # specify world parameters\n",
    "# num_cols = 10\n",
    "# num_rows = 10\n",
    "# obstructions = np.array([[0,7],[1,1],[1,2],[1,3],[1,7],[2,1],[2,3],\n",
    "#                          [2,7],[3,1],[3,3],[3,5],[4,3],[4,5],[4,7],\n",
    "#                          [5,3],[5,7],[5,9],[6,3],[6,9],[7,1],[7,6],\n",
    "#                          [7,7],[7,8],[7,9],[8,1],[8,5],[8,6],[9,1]])\n",
    "# bad_states = np.array([[1,9],[4,2],[4,4],[7,5],[9,9]])\n",
    "# restart_states = np.array([[3,7],[8,2]])\n",
    "# start_state = np.array([[3,6]])\n",
    "# goal_states = np.array([[0,9],[2,2],[8,7]])\n",
    "\n",
    "# # create model\n",
    "# gw = GridWorld(num_rows=num_rows,\n",
    "#                num_cols=num_cols,\n",
    "#                start_state=start_state,\n",
    "#                goal_states=goal_states, wind = False)\n",
    "# gw.add_obstructions(obstructed_states=obstructions,\n",
    "#                     bad_states=bad_states,\n",
    "#                     restart_states=restart_states)\n",
    "# gw.add_rewards(step_reward=-1,\n",
    "#                goal_reward=10,\n",
    "#                bad_state_reward=-6,\n",
    "#                restart_state_reward=-100)\n",
    "# gw.add_transition_probability(p_good_transition=0.7,\n",
    "#                               bias=0.5)\n",
    "# env = gw.create_gridworld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UdRce8oMZNb",
    "outputId": "ee3858e1-e109-42e6-80eb-336702f708e3"
   },
   "outputs": [],
   "source": [
    "# print(\"Number of actions\", env.num_actions) #0 -> UP, 1-> DOWN, 2 -> LEFT, 3-> RIGHT\n",
    "# print(\"Number of states\", env.num_states)\n",
    "# print(\"start state\", env.start_state_seq)\n",
    "# print(\"goal state(s)\", env.goal_states_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "UP = 1\n",
    "DOWN = 0\n",
    "LEFT = 2\n",
    "RIGHT = 3\n",
    "def plot_Q(Q, message = \"Q plot\", save_file=None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.title(message)\n",
    "    plt.pcolor(Q.max(-1), edgecolors='k', linewidths=2)\n",
    "    plt.colorbar()\n",
    "    def x_direct(a):\n",
    "        if a in [UP, DOWN]:\n",
    "            return 0\n",
    "        return 1 if a == RIGHT else -1\n",
    "    def y_direct(a):\n",
    "        if a in [RIGHT, LEFT]:\n",
    "            return 0\n",
    "        return 1 if a == UP else -1\n",
    "    policy = Q.argmax(-1)\n",
    "    policyx = np.vectorize(x_direct)(policy)\n",
    "    policyy = np.vectorize(y_direct)(policy)\n",
    "    idx = np.indices(policy.shape)\n",
    "    plt.quiver(idx[1].ravel()+0.5, idx[0].ravel()+0.5, policyx.ravel(), policyy.ravel(), pivot=\"middle\", color='red')\n",
    "    if(save_file != None):\n",
    "        plt.savefig(save_file)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    # return fig\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def sarsa(env,Q,gamma,alpha,epsilon,choose_action,plot_heat = False,max_timesteps=100) :\n",
    "  episode_rewards = []\n",
    "  state_visit_count = np.zeros((env.num_rows, env.num_cols))\n",
    "  steps_to_completion = []\n",
    "  steps = 0\n",
    "  for steps in tqdm(range(episodes)):\n",
    "    timesteps=0\n",
    "    env.reset()\n",
    "    current_state = env.start_state_seq[0]\n",
    "    current_action = choose_action(env,Q,current_state,hyper=epsilon)\n",
    "    rewards = []\n",
    "    tot_reward = 0 \n",
    "    while timesteps<max_timesteps :\n",
    "      timesteps+=1\n",
    "      next_state,reward = env.step(current_state,current_action)\n",
    "      next_action = choose_action(env,Q,next_state, hyper=epsilon)\n",
    "      # best next action\n",
    "#       best_next_action = np.argmax(Q[next_state//env.num_rows,next_state%env.num_cols])\n",
    "      Q[int(current_state/(env.num_cols)), current_state%(env.num_cols), current_action] += alpha*(reward[0] + gamma*Q[int(next_state/(env.num_cols)), next_state%(env.num_cols), next_action] - Q[int(current_state/(env.num_cols)), current_state%(env.num_cols), current_action])\n",
    "      rewards.append(reward[0])\n",
    "      tot_reward = tot_reward + reward[0]\n",
    "      # print(reward)\n",
    "      if reward == env.r_goal :\n",
    "        break\n",
    "      # print(current_state)\n",
    "      current_state = next_state\n",
    "      current_action = next_action\n",
    "      state_visit_count[int(current_state/(env.num_cols)), current_state%(env.num_cols)]+=1\n",
    "    episode_rewards.append(tot_reward)\n",
    "    steps_to_completion.append(timesteps)\n",
    "\n",
    "    if (steps+1)%10 == 0 and plot_heat:\n",
    "      clear_output(wait=True)\n",
    "      plot_Q(Q, message = \"Episode %d: Reward: %f, Steps: %.2f, Qmax: %.2f, Qmin: %.2f\"%(steps+1, np.mean(episode_rewards[steps-10+1:steps]),\n",
    "                                                                           np.mean(steps_to_completion[steps-10+1:steps]),\n",
    "                                                                           Q.max(), Q.min()))\n",
    "  return Q, episode_rewards, steps_to_completion,state_visit_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_Q(env,Q, max_timesteps=100) :\n",
    "    episode_rewards = []\n",
    "    steps_to_completion = []\n",
    "    steps = 0\n",
    "    episodes = 100\n",
    "    for steps in tqdm(range(episodes)):\n",
    "        timesteps=0\n",
    "        env.reset()\n",
    "        current_state = env.start_state_seq[0]\n",
    "        current_action = np.argmax(Q[int(current_state/(env.num_cols)), current_state%(env.num_cols)])\n",
    "        rewards = []\n",
    "        tot_reward = 0 \n",
    "        while timesteps<max_timesteps :\n",
    "            timesteps+=1\n",
    "            next_state,reward = env.step(current_state,current_action)\n",
    "            next_action = np.argmax(Q[int(next_state/(env.num_cols)), next_state%(env.num_cols)])\n",
    "\n",
    "            rewards.append(reward[0])\n",
    "            tot_reward = tot_reward + reward[0]\n",
    "            # print(reward)\n",
    "            if reward == env.r_goal :\n",
    "                break\n",
    "            # print(current_state)\n",
    "            current_state = next_state\n",
    "            current_action = next_action\n",
    "        episode_rewards.append(tot_reward)\n",
    "        steps_to_completion.append(timesteps)\n",
    "\n",
    "    return np.mean(episode_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify world parameters\n",
    "num_cols = 10\n",
    "num_rows = 10\n",
    "obstructions = np.array([[0,7],[1,1],[1,2],[1,3],[1,7],[2,1],[2,3],\n",
    "                         [2,7],[3,1],[3,3],[3,5],[4,3],[4,5],[4,7],\n",
    "                         [5,3],[5,7],[5,9],[6,3],[6,9],[7,1],[7,6],\n",
    "                         [7,7],[7,8],[7,9],[8,1],[8,5],[8,6],[9,1]])\n",
    "bad_states = np.array([[1,9],[4,2],[4,4],[7,5],[9,9]])\n",
    "restart_states = np.array([[3,7],[8,2]])\n",
    "start_state = np.array([start_state])\n",
    "goal_states = np.array([[0,9],[2,2],[8,7]])\n",
    "# create model\n",
    "gw = GridWorld(num_rows=num_rows,\n",
    "               num_cols=num_cols,\n",
    "               start_state=start_state,\n",
    "               goal_states=goal_states, wind = wind)\n",
    "gw.add_obstructions(obstructed_states=obstructions,\n",
    "                    bad_states=bad_states,\n",
    "                    restart_states=restart_states)\n",
    "gw.add_rewards(step_reward=-1,\n",
    "               goal_reward=10,\n",
    "               bad_state_reward=-6,\n",
    "               restart_state_reward=-100)\n",
    "gw.add_transition_probability(p_good_transition=p,\n",
    "                              bias=0.5)\n",
    "env = gw.create_gridworld()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:18<00:00, 1069.35it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1030.93it/s]\n",
      "100%|██████████| 20000/20000 [01:04<00:00, 312.34it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 392.15it/s]\n",
      "100%|██████████| 20000/20000 [01:06<00:00, 302.62it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 467.30it/s]\n",
      "100%|██████████| 20000/20000 [00:24<00:00, 817.59it/s] \n",
      "100%|██████████| 100/100 [00:00<00:00, 1388.97it/s]\n",
      "100%|██████████| 20000/20000 [01:17<00:00, 258.10it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 387.60it/s]\n",
      "100%|██████████| 20000/20000 [01:25<00:00, 234.93it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 380.23it/s]\n",
      "100%|██████████| 20000/20000 [00:14<00:00, 1349.44it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2083.45it/s]\n",
      "100%|██████████| 20000/20000 [00:16<00:00, 1231.15it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1492.52it/s]\n",
      "100%|██████████| 20000/20000 [01:18<00:00, 255.56it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 409.84it/s]\n",
      "100%|██████████| 20000/20000 [00:13<00:00, 1468.43it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1960.83it/s]\n",
      "100%|██████████| 20000/20000 [00:13<00:00, 1434.31it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1851.90it/s]\n",
      "100%|██████████| 20000/20000 [00:17<00:00, 1130.77it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2127.63it/s]\n",
      "100%|██████████| 20000/20000 [00:13<00:00, 1457.09it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1886.61it/s]\n",
      "100%|██████████| 20000/20000 [00:13<00:00, 1452.43it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2000.01it/s]\n",
      "100%|██████████| 20000/20000 [00:17<00:00, 1169.93it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2272.01it/s]\n",
      "100%|██████████| 20000/20000 [00:24<00:00, 812.81it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1063.84it/s]\n",
      "100%|██████████| 20000/20000 [01:20<00:00, 248.61it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 389.10it/s]\n",
      "100%|██████████| 20000/20000 [01:23<00:00, 238.42it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 392.16it/s]\n",
      "100%|██████████| 20000/20000 [00:25<00:00, 798.59it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1063.81it/s]\n",
      "100%|██████████| 20000/20000 [01:21<00:00, 246.85it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 392.16it/s]\n",
      "100%|██████████| 20000/20000 [01:24<00:00, 236.93it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 384.62it/s]\n",
      "100%|██████████| 20000/20000 [00:24<00:00, 800.32it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1162.85it/s]\n",
      "100%|██████████| 20000/20000 [01:03<00:00, 316.56it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 363.64it/s]\n",
      "100%|██████████| 20000/20000 [01:21<00:00, 244.03it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 364.96it/s]\n",
      "100%|██████████| 20000/20000 [00:13<00:00, 1474.60it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2222.27it/s]\n",
      "100%|██████████| 20000/20000 [00:15<00:00, 1312.34it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2272.66it/s]\n",
      "100%|██████████| 20000/20000 [00:19<00:00, 1051.69it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1818.17it/s]\n",
      "100%|██████████| 20000/20000 [00:14<00:00, 1427.65it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2499.54it/s]\n",
      "100%|██████████| 20000/20000 [00:14<00:00, 1344.18it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1922.96it/s]\n",
      "100%|██████████| 20000/20000 [00:18<00:00, 1099.53it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2380.87it/s]\n",
      "100%|██████████| 20000/20000 [00:26<00:00, 762.08it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1176.47it/s]\n",
      "100%|██████████| 20000/20000 [01:19<00:00, 251.27it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 446.43it/s]\n",
      "100%|██████████| 20000/20000 [01:23<00:00, 238.76it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 393.70it/s]\n",
      "100%|██████████| 20000/20000 [00:25<00:00, 785.67it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1020.40it/s]\n",
      "100%|██████████| 20000/20000 [01:22<00:00, 243.47it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 375.94it/s]\n",
      "100%|██████████| 20000/20000 [01:24<00:00, 237.08it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 401.62it/s]\n",
      "100%|██████████| 20000/20000 [00:23<00:00, 867.08it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1219.53it/s]\n",
      "100%|██████████| 20000/20000 [01:13<00:00, 272.46it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 344.83it/s]\n",
      "100%|██████████| 20000/20000 [01:23<00:00, 238.91it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 367.66it/s]\n",
      "100%|██████████| 20000/20000 [00:13<00:00, 1466.71it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2222.30it/s]\n",
      "100%|██████████| 20000/20000 [00:15<00:00, 1262.79it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1612.89it/s]\n",
      "100%|██████████| 20000/20000 [00:20<00:00, 986.92it/s] \n",
      "100%|██████████| 100/100 [00:00<00:00, 1785.68it/s]\n",
      "100%|██████████| 20000/20000 [00:13<00:00, 1467.14it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2272.90it/s]\n",
      "100%|██████████| 20000/20000 [00:14<00:00, 1349.71it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1886.83it/s]\n",
      "100%|██████████| 20000/20000 [00:18<00:00, 1071.87it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2173.89it/s]\n",
      "100%|██████████| 20000/20000 [00:24<00:00, 804.44it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1041.70it/s]\n",
      "100%|██████████| 20000/20000 [01:22<00:00, 242.35it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 341.30it/s]\n",
      "100%|██████████| 20000/20000 [01:24<00:00, 236.73it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 330.03it/s]\n",
      "100%|██████████| 20000/20000 [00:25<00:00, 783.27it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 943.42it/s]\n",
      "100%|██████████| 20000/20000 [01:21<00:00, 245.17it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 396.83it/s]\n",
      "100%|██████████| 20000/20000 [01:24<00:00, 236.45it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 411.53it/s]\n",
      "100%|██████████| 20000/20000 [00:25<00:00, 789.64it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1176.49it/s]\n",
      "100%|██████████| 20000/20000 [01:21<00:00, 245.73it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 404.86it/s]\n",
      "100%|██████████| 20000/20000 [01:30<00:00, 220.68it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 305.81it/s]\n",
      "100%|██████████| 20000/20000 [00:20<00:00, 988.68it/s] \n",
      "100%|██████████| 100/100 [00:00<00:00, 1282.05it/s]\n",
      "100%|██████████| 20000/20000 [00:15<00:00, 1278.20it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2173.99it/s]\n",
      "100%|██████████| 20000/20000 [00:24<00:00, 818.40it/s] \n",
      "100%|██████████| 100/100 [00:00<00:00, 1470.60it/s]\n",
      "100%|██████████| 20000/20000 [00:13<00:00, 1454.44it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 3030.26it/s]\n",
      "100%|██████████| 20000/20000 [00:15<00:00, 1326.79it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2222.27it/s]\n",
      "100%|██████████| 20000/20000 [00:19<00:00, 1051.75it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2127.72it/s]\n",
      "100%|██████████| 20000/20000 [00:25<00:00, 799.71it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1149.41it/s]\n",
      "100%|██████████| 20000/20000 [01:20<00:00, 249.16it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 446.43it/s]\n",
      "100%|██████████| 20000/20000 [01:25<00:00, 233.72it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 404.86it/s]\n",
      "100%|██████████| 20000/20000 [00:25<00:00, 790.64it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1020.43it/s]\n",
      "100%|██████████| 20000/20000 [01:21<00:00, 246.70it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 359.71it/s]\n",
      "100%|██████████| 20000/20000 [01:28<00:00, 226.24it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 383.14it/s]\n",
      "100%|██████████| 20000/20000 [00:29<00:00, 670.44it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 427.35it/s]\n",
      "100%|██████████| 20000/20000 [01:28<00:00, 226.63it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 395.25it/s]\n",
      "100%|██████████| 20000/20000 [01:28<00:00, 226.81it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 343.64it/s]\n",
      "100%|██████████| 20000/20000 [00:24<00:00, 800.70it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1123.64it/s]\n",
      "100%|██████████| 20000/20000 [00:22<00:00, 886.88it/s] \n",
      "100%|██████████| 100/100 [00:00<00:00, 2000.01it/s]\n",
      "100%|██████████| 20000/20000 [00:47<00:00, 425.15it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 1818.12it/s]\n",
      "100%|██████████| 20000/20000 [00:13<00:00, 1501.95it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2000.06it/s]\n",
      "100%|██████████| 20000/20000 [00:14<00:00, 1344.18it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2041.50it/s]\n",
      "100%|██████████| 20000/20000 [00:19<00:00, 1029.71it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2173.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004 0.8999999999999999 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tune hyperparameters\n",
    "from math import inf\n",
    "seed = 42\n",
    "max_valuation = -inf\n",
    "for alpha in alphas:\n",
    "    for gamma in gammas:\n",
    "        for epsilon in epsilons:\n",
    "            Q = np.zeros((env.num_rows, env.num_cols, env.num_actions))\n",
    "            rg = np.random.RandomState(seed)\n",
    "            if(conf % 2 == 0):\n",
    "                Q, rewards, steps, _ = sarsa(env, Q,gamma,alpha,epsilon,choose_action = choose_action_softmax)\n",
    "            else:\n",
    "                Q, rewards, steps, _ = sarsa(env, Q,gamma,alpha,epsilon,choose_action = choose_action_epsilon)\n",
    "            valuation = eval_Q(env,Q)\n",
    "            if(valuation >= max_valuation):\n",
    "                opt_alpha = alpha\n",
    "                opt_gamma = gamma\n",
    "                opt_epsilon = epsilon\n",
    "                max_valuation = valuation\n",
    "            \n",
    "print(opt_alpha,opt_gamma,opt_epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:13<00:00, 1443.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:13<00:00, 1443.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:13<00:00, 1434.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence of rewards approx.  -11.3\n",
      "Convergence of time steps approx.  16.799999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Q_avgs, reward_avgs, steps_avgs = [], [], []\n",
    "num_expts = 3\n",
    "\n",
    "alpha = opt_alpha\n",
    "gamma = opt_gamma\n",
    "epsilon = opt_epsilon\n",
    "episodes = 20000\n",
    "\n",
    "for i in range(num_expts):\n",
    "    print(\"Experiment: %d\"%(i+1))\n",
    "    Q = np.zeros((env.num_rows, env.num_cols, env.num_actions))\n",
    "    rg = np.random.RandomState(i)\n",
    "    if(conf % 2 == 0):\n",
    "        Q, rewards, steps, _ = sarsa(env, Q,gamma,alpha,epsilon,choose_action = choose_action_softmax)\n",
    "    else:\n",
    "        Q, rewards, steps, _ = sarsa(env, Q,gamma,alpha,epsilon,choose_action = choose_action_epsilon)\n",
    "    Q_avgs.append(Q.copy())\n",
    "    reward_avgs.append(rewards)\n",
    "    steps_avgs.append(steps)\n",
    "    \n",
    "conv_rewards = np.mean(np.average(reward_avgs,axis=0)[episodes-10:episodes])\n",
    "conv_steps = np.mean(np.average(steps_avgs,axis=0)[episodes-10:episodes])\n",
    "print(\"Convergence of rewards approx. \", conv_rewards)\n",
    "print(\"Convergence of time steps approx. \", conv_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    os.mkdir('conf'+str(conf))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "plt.style.use('seaborn-poster')\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Number of steps to Goal')\n",
    "plt.plot(np.arange(episodes),np.average(steps_avgs, 0))\n",
    "# plt.show()\n",
    "plt.savefig('conf'+str(conf)+'/steps-vs-episodes.jpeg')\n",
    "plt.close()\n",
    "plt.style.use('seaborn-poster')\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.plot(np.arange(episodes),np.average(reward_avgs, 0))\n",
    "# plt.show()\n",
    "plt.savefig('conf'+str(conf)+'/rewards-vs-episodes.jpeg')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:13<00:00, 1528.90it/s]\n"
     ]
    }
   ],
   "source": [
    "alpha = opt_alpha\n",
    "gamma = opt_gamma\n",
    "epsilon = opt_epsilon\n",
    "episodes = 20000\n",
    "\n",
    "Q = np.zeros((env.num_rows, env.num_cols, env.num_actions))\n",
    "rg = np.random.RandomState(i)\n",
    "if(conf % 2 == 0):\n",
    "    Q, rewards, steps, _ = sarsa(env, Q,gamma,alpha,epsilon,choose_action = choose_action_softmax)\n",
    "else:\n",
    "    Q, rewards, steps, _ = sarsa(env, Q,gamma,alpha,epsilon,choose_action = choose_action_epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 921.6x633.6 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plot = sns.heatmap(state_visit_count)\n",
    "plot.invert_yaxis()\n",
    "fig = plot.get_figure()\n",
    "fig.savefig('conf'+str(conf)+'/heatmap-state-visit-count.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Q(Q, save_file='conf'+str(conf)+'/heatmap-policy.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 3225.87it/s]\n"
     ]
    }
   ],
   "source": [
    "valuation = eval_Q(env,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf = 17\n",
    "\n",
    "with open('conf'+str(conf)+'/hyperparameter-tuning-results.txt', 'w') as f:\n",
    "    f.write('conf '+ str(conf) + '\\n')\n",
    "    f.write('wind = ' + str(wind) + '\\n')\n",
    "    f.write('start state = ' + str(start_state) + '\\n')\n",
    "    f.write('p = ' + str(p) + '\\n')\n",
    "    f.write('strategy = e_greedy\\n\\n')\n",
    "    f.write('opt_alpha = ' + str(opt_alpha) + '\\n')\n",
    "    f.write('opt_gamma = ' + str(opt_gamma)+'\\n')\n",
    "    f.write('opt_epsilon = ' + str(opt_epsilon)+'\\n')\n",
    "    f.write('\\nconvergence: '+'\\n')\n",
    "    f.write('rewards = ' + str(conv_rewards)+'\\n')\n",
    "    f.write('steps = ' + str(conv_steps)+'\\n')\n",
    "    f.write('\\nevaluation: ' + str(valuation)+'\\n')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PA1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
